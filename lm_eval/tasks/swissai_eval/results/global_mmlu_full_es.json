{
  "config": {
    "model": "huggingface",
    "model_args": {
      "pretrained": "sshleifer/tiny-gpt2"
    },
    "model_num_parameters": 102714,
    "model_dtype": "float32",
    "model_revision": "main",
    "model_sha": "5f91d94bd9cd7190a9f3216ff93cd1dd95f2c7be",
    "batch_size": 1,
    "batch_sizes": [],
    "device": "cuda:0",
    "use_cache": null,
    "limit": 1,
    "bootstrap_iters": 100000,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "results": {
    "global_mmlu_full_es": {
      "acc,none": 0.14035087719298245,
      "acc_stderr,none": "N/A",
      "alias": "global_mmlu_full_es"
    },
    "global_mmlu_full_es_humanities": {
      "acc,none": 0.24615384615384617,
      "acc_stderr,none": "N/A",
      "alias": " - global_mmlu_full_es_humanities"
    },
    "global_mmlu_full_es_formal_logic": {
      "alias": "  - global_mmlu_full_es_formal_logic",
      "acc,none": 0.8,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_european_history": {
      "alias": "  - global_mmlu_full_es_high_school_european_history",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_us_history": {
      "alias": "  - global_mmlu_full_es_high_school_us_history",
      "acc,none": 0.8,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_world_history": {
      "alias": "  - global_mmlu_full_es_high_school_world_history",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_international_law": {
      "alias": "  - global_mmlu_full_es_international_law",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_jurisprudence": {
      "alias": "  - global_mmlu_full_es_jurisprudence",
      "acc,none": 0.8,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_logical_fallacies": {
      "alias": "  - global_mmlu_full_es_logical_fallacies",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_moral_disputes": {
      "alias": "  - global_mmlu_full_es_moral_disputes",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_moral_scenarios": {
      "alias": "  - global_mmlu_full_es_moral_scenarios",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_philosophy": {
      "alias": "  - global_mmlu_full_es_philosophy",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_prehistory": {
      "alias": "  - global_mmlu_full_es_prehistory",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_professional_law": {
      "alias": "  - global_mmlu_full_es_professional_law",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_world_religions": {
      "alias": "  - global_mmlu_full_es_world_religions",
      "acc,none": 0.8,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_other": {
      "acc,none": 0.06153846153846154,
      "acc_stderr,none": "N/A",
      "alias": " - global_mmlu_full_es_other"
    },
    "global_mmlu_full_es_business_ethics": {
      "alias": "  - global_mmlu_full_es_business_ethics",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_clinical_knowledge": {
      "alias": "  - global_mmlu_full_es_clinical_knowledge",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_college_medicine": {
      "alias": "  - global_mmlu_full_es_college_medicine",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_global_facts": {
      "alias": "  - global_mmlu_full_es_global_facts",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_human_aging": {
      "alias": "  - global_mmlu_full_es_human_aging",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_management": {
      "alias": "  - global_mmlu_full_es_management",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_marketing": {
      "alias": "  - global_mmlu_full_es_marketing",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_medical_genetics": {
      "alias": "  - global_mmlu_full_es_medical_genetics",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_miscellaneous": {
      "alias": "  - global_mmlu_full_es_miscellaneous",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_nutrition": {
      "alias": "  - global_mmlu_full_es_nutrition",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_professional_accounting": {
      "alias": "  - global_mmlu_full_es_professional_accounting",
      "acc,none": 0.8,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_professional_medicine": {
      "alias": "  - global_mmlu_full_es_professional_medicine",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_virology": {
      "alias": "  - global_mmlu_full_es_virology",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_social_sciences": {
      "acc,none": 0.06666666666666667,
      "acc_stderr,none": "N/A",
      "alias": " - global_mmlu_full_es_social_sciences"
    },
    "global_mmlu_full_es_econometrics": {
      "alias": "  - global_mmlu_full_es_econometrics",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_geography": {
      "alias": "  - global_mmlu_full_es_high_school_geography",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_government_and_politics": {
      "alias": "  - global_mmlu_full_es_high_school_government_and_politics",
      "acc,none": 0.8,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_macroeconomics": {
      "alias": "  - global_mmlu_full_es_high_school_macroeconomics",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_microeconomics": {
      "alias": "  - global_mmlu_full_es_high_school_microeconomics",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_psychology": {
      "alias": "  - global_mmlu_full_es_high_school_psychology",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_human_sexuality": {
      "alias": "  - global_mmlu_full_es_human_sexuality",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_professional_psychology": {
      "alias": "  - global_mmlu_full_es_professional_psychology",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_public_relations": {
      "alias": "  - global_mmlu_full_es_public_relations",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_security_studies": {
      "alias": "  - global_mmlu_full_es_security_studies",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_sociology": {
      "alias": "  - global_mmlu_full_es_sociology",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_us_foreign_policy": {
      "alias": "  - global_mmlu_full_es_us_foreign_policy",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_stem": {
      "acc,none": 0.16842105263157894,
      "acc_stderr,none": "N/A",
      "alias": " - global_mmlu_full_es_stem"
    },
    "global_mmlu_full_es_abstract_algebra": {
      "alias": "  - global_mmlu_full_es_abstract_algebra",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_anatomy": {
      "alias": "  - global_mmlu_full_es_anatomy",
      "acc,none": 0.8,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_astronomy": {
      "alias": "  - global_mmlu_full_es_astronomy",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_college_biology": {
      "alias": "  - global_mmlu_full_es_college_biology",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_college_chemistry": {
      "alias": "  - global_mmlu_full_es_college_chemistry",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_college_computer_science": {
      "alias": "  - global_mmlu_full_es_college_computer_science",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_college_mathematics": {
      "alias": "  - global_mmlu_full_es_college_mathematics",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_college_physics": {
      "alias": "  - global_mmlu_full_es_college_physics",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_computer_security": {
      "alias": "  - global_mmlu_full_es_computer_security",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_conceptual_physics": {
      "alias": "  - global_mmlu_full_es_conceptual_physics",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_electrical_engineering": {
      "alias": "  - global_mmlu_full_es_electrical_engineering",
      "acc,none": 0.8,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_elementary_mathematics": {
      "alias": "  - global_mmlu_full_es_elementary_mathematics",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_biology": {
      "alias": "  - global_mmlu_full_es_high_school_biology",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_chemistry": {
      "alias": "  - global_mmlu_full_es_high_school_chemistry",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_computer_science": {
      "alias": "  - global_mmlu_full_es_high_school_computer_science",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_mathematics": {
      "alias": "  - global_mmlu_full_es_high_school_mathematics",
      "acc,none": 0.8,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_physics": {
      "alias": "  - global_mmlu_full_es_high_school_physics",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_high_school_statistics": {
      "alias": "  - global_mmlu_full_es_high_school_statistics",
      "acc,none": 0.0,
      "acc_stderr,none": "N/A"
    },
    "global_mmlu_full_es_machine_learning": {
      "alias": "  - global_mmlu_full_es_machine_learning",
      "acc,none": 0.8,
      "acc_stderr,none": "N/A"
    }
  },
  "groups": {
    "global_mmlu_full_es": {
      "acc,none": 0.14035087719298245,
      "acc_stderr,none": "N/A",
      "alias": "global_mmlu_full_es"
    },
    "global_mmlu_full_es_humanities": {
      "acc,none": 0.24615384615384617,
      "acc_stderr,none": "N/A",
      "alias": " - global_mmlu_full_es_humanities"
    },
    "global_mmlu_full_es_other": {
      "acc,none": 0.06153846153846154,
      "acc_stderr,none": "N/A",
      "alias": " - global_mmlu_full_es_other"
    },
    "global_mmlu_full_es_social_sciences": {
      "acc,none": 0.06666666666666667,
      "acc_stderr,none": "N/A",
      "alias": " - global_mmlu_full_es_social_sciences"
    },
    "global_mmlu_full_es_stem": {
      "acc,none": 0.16842105263157894,
      "acc_stderr,none": "N/A",
      "alias": " - global_mmlu_full_es_stem"
    }
  },
  "group_subtasks": {
    "global_mmlu_full_es_humanities": [
      "global_mmlu_full_es_high_school_world_history",
      "global_mmlu_full_es_formal_logic",
      "global_mmlu_full_es_international_law",
      "global_mmlu_full_es_moral_disputes",
      "global_mmlu_full_es_world_religions",
      "global_mmlu_full_es_jurisprudence",
      "global_mmlu_full_es_logical_fallacies",
      "global_mmlu_full_es_high_school_us_history",
      "global_mmlu_full_es_high_school_european_history",
      "global_mmlu_full_es_philosophy",
      "global_mmlu_full_es_moral_scenarios",
      "global_mmlu_full_es_prehistory",
      "global_mmlu_full_es_professional_law"
    ],
    "global_mmlu_full_es_social_sciences": [
      "global_mmlu_full_es_high_school_psychology",
      "global_mmlu_full_es_public_relations",
      "global_mmlu_full_es_high_school_macroeconomics",
      "global_mmlu_full_es_high_school_government_and_politics",
      "global_mmlu_full_es_high_school_microeconomics",
      "global_mmlu_full_es_sociology",
      "global_mmlu_full_es_econometrics",
      "global_mmlu_full_es_human_sexuality",
      "global_mmlu_full_es_professional_psychology",
      "global_mmlu_full_es_high_school_geography",
      "global_mmlu_full_es_us_foreign_policy",
      "global_mmlu_full_es_security_studies"
    ],
    "global_mmlu_full_es_other": [
      "global_mmlu_full_es_management",
      "global_mmlu_full_es_virology",
      "global_mmlu_full_es_human_aging",
      "global_mmlu_full_es_nutrition",
      "global_mmlu_full_es_professional_medicine",
      "global_mmlu_full_es_medical_genetics",
      "global_mmlu_full_es_professional_accounting",
      "global_mmlu_full_es_clinical_knowledge",
      "global_mmlu_full_es_global_facts",
      "global_mmlu_full_es_miscellaneous",
      "global_mmlu_full_es_marketing",
      "global_mmlu_full_es_college_medicine",
      "global_mmlu_full_es_business_ethics"
    ],
    "global_mmlu_full_es_stem": [
      "global_mmlu_full_es_college_computer_science",
      "global_mmlu_full_es_college_physics",
      "global_mmlu_full_es_high_school_chemistry",
      "global_mmlu_full_es_astronomy",
      "global_mmlu_full_es_elementary_mathematics",
      "global_mmlu_full_es_anatomy",
      "global_mmlu_full_es_college_mathematics",
      "global_mmlu_full_es_high_school_computer_science",
      "global_mmlu_full_es_high_school_mathematics",
      "global_mmlu_full_es_computer_security",
      "global_mmlu_full_es_abstract_algebra",
      "global_mmlu_full_es_conceptual_physics",
      "global_mmlu_full_es_high_school_statistics",
      "global_mmlu_full_es_machine_learning",
      "global_mmlu_full_es_high_school_biology",
      "global_mmlu_full_es_electrical_engineering",
      "global_mmlu_full_es_college_chemistry",
      "global_mmlu_full_es_college_biology",
      "global_mmlu_full_es_high_school_physics"
    ],
    "global_mmlu_full_es": [
      "global_mmlu_full_es_stem",
      "global_mmlu_full_es_other",
      "global_mmlu_full_es_social_sciences",
      "global_mmlu_full_es_humanities"
    ]
  },
  "configs": {
    "global_mmlu_full_es_abstract_algebra": {
      "task": "global_mmlu_full_es_abstract_algebra",
      "tag": "global_mmlu_full_es_stem_tasks",
      "dataset_path": "CohereForAI/Global-MMLU",
      "dataset_name": "es",
      "test_split": "test",
      "fewshot_split": "dev",
      "process_docs": "functools.partial(<function process_docs at 0x7a2f38ac00e0>, subject='abstract_algebra')",
      "doc_to_text": "{{question.strip()}}\nA. {{option_a}}\nB. {{option_b}}\nC. {{option_c}}\nD. {{option_d}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "global_mmlu_full_es_anatomy": {
      "task": "global_mmlu_full_es_anatomy",
      "tag": "global_mmlu_full_es_stem_tasks",
      "dataset_path": "CohereForAI/Global-MMLU",
      "dataset_name": "es",
      "test_split": "test",
      "fewshot_split": "dev",
      "process_docs": "functools.partial(<function process_docs at 0x7a2fb0b4bf60>, subject='anatomy')",
      "doc_to_text": "{{question.strip()}}\nA. {{option_a}}\nB. {{option_b}}\nC. {{option_c}}\nD. {{option_d}}\nAnswer:",
      "doc_to_target": "answer",
      "unsafe_code": false,
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    }
  }
}