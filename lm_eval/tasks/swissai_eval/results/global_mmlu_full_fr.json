{
    "config": {
        "model": "huggingface",
        "model_args": {"pretrained": "sshleifer/tiny-gpt2"},
        "model_num_parameters": 102714,
        "model_dtype": "float32",
        "model_revision": "main",
        "model_sha": "5f91d94bd9cd7190a9f3216ff93cd1dd95f2c7be",
        "batch_size": 1,
        "batch_sizes": [],
        "device": "cuda:0",
        "use_cache": null,
        "limit": 1,
        "bootstrap_iters": 100000,
        "gen_kwargs": null,
        "random_seed": 0,
        "numpy_seed": 1234,
        "torch_seed": 1234,
        "fewshot_seed": 1234
      },
      "results": {"global_mmlu_full_fr": {"acc,none": 0.17543859649122806, "acc_stderr,none": "N/A", "alias": "global_mmlu_full_fr"}, "global_mmlu_full_fr_humanities": {"acc,none": 0.3076923076923077, "acc_stderr,none": "N/A", "alias": " - global_mmlu_full_fr_humanities"}, "global_mmlu_full_fr_formal_logic": {"alias": "  - global_mmlu_full_fr_formal_logic", "acc,none": 1.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_european_history": {"alias": "  - global_mmlu_full_fr_high_school_european_history", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_us_history": {"alias": "  - global_mmlu_full_fr_high_school_us_history", "acc,none": 1.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_world_history": {"alias": "  - global_mmlu_full_fr_high_school_world_history", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_international_law": {"alias": "  - global_mmlu_full_fr_international_law", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_jurisprudence": {"alias": "  - global_mmlu_full_fr_jurisprudence", "acc,none": 1.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_logical_fallacies": {"alias": "  - global_mmlu_full_fr_logical_fallacies", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_moral_disputes": {"alias": "  - global_mmlu_full_fr_moral_disputes", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_moral_scenarios": {"alias": "  - global_mmlu_full_fr_moral_scenarios", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_philosophy": {"alias": "  - global_mmlu_full_fr_philosophy", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_prehistory": {"alias": "  - global_mmlu_full_fr_prehistory", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_professional_law": {"alias": "  - global_mmlu_full_fr_professional_law", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_world_religions": {"alias": "  - global_mmlu_full_fr_world_religions", "acc,none": 1.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_other": {"acc,none": 0.07692307692307693, "acc_stderr,none": "N/A", "alias": " - global_mmlu_full_fr_other"}, "global_mmlu_full_fr_business_ethics": {"alias": "  - global_mmlu_full_fr_business_ethics", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_clinical_knowledge": {"alias": "  - global_mmlu_full_fr_clinical_knowledge", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_college_medicine": {"alias": "  - global_mmlu_full_fr_college_medicine", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_global_facts": {"alias": "  - global_mmlu_full_fr_global_facts", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_human_aging": {"alias": "  - global_mmlu_full_fr_human_aging", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_management": {"alias": "  - global_mmlu_full_fr_management", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_marketing": {"alias": "  - global_mmlu_full_fr_marketing", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_medical_genetics": {"alias": "  - global_mmlu_full_fr_medical_genetics", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_miscellaneous": {"alias": "  - global_mmlu_full_fr_miscellaneous", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_nutrition": {"alias": "  - global_mmlu_full_fr_nutrition", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_professional_accounting": {"alias": "  - global_mmlu_full_fr_professional_accounting", "acc,none": 1.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_professional_medicine": {"alias": "  - global_mmlu_full_fr_professional_medicine", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_virology": {"alias": "  - global_mmlu_full_fr_virology", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_social_sciences": {"acc,none": 0.08333333333333333, "acc_stderr,none": "N/A", "alias": " - global_mmlu_full_fr_social_sciences"}, "global_mmlu_full_fr_econometrics": {"alias": "  - global_mmlu_full_fr_econometrics", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_geography": {"alias": "  - global_mmlu_full_fr_high_school_geography", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_government_and_politics": {"alias": "  - global_mmlu_full_fr_high_school_government_and_politics", "acc,none": 1.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_macroeconomics": {"alias": "  - global_mmlu_full_fr_high_school_macroeconomics", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_microeconomics": {"alias": "  - global_mmlu_full_fr_high_school_microeconomics", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_psychology": {"alias": "  - global_mmlu_full_fr_high_school_psychology", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_human_sexuality": {"alias": "  - global_mmlu_full_fr_human_sexuality", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_professional_psychology": {"alias": "  - global_mmlu_full_fr_professional_psychology", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_public_relations": {"alias": "  - global_mmlu_full_fr_public_relations", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_security_studies": {"alias": "  - global_mmlu_full_fr_security_studies", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_sociology": {"alias": "  - global_mmlu_full_fr_sociology", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_us_foreign_policy": {"alias": "  - global_mmlu_full_fr_us_foreign_policy", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_stem": {"acc,none": 0.21052631578947367, "acc_stderr,none": "N/A", "alias": " - global_mmlu_full_fr_stem"}, "global_mmlu_full_fr_abstract_algebra": {"alias": "  - global_mmlu_full_fr_abstract_algebra", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_anatomy": {"alias": "  - global_mmlu_full_fr_anatomy", "acc,none": 1.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_astronomy": {"alias": "  - global_mmlu_full_fr_astronomy", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_college_biology": {"alias": "  - global_mmlu_full_fr_college_biology", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_college_chemistry": {"alias": "  - global_mmlu_full_fr_college_chemistry", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_college_computer_science": {"alias": "  - global_mmlu_full_fr_college_computer_science", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_college_mathematics": {"alias": "  - global_mmlu_full_fr_college_mathematics", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_college_physics": {"alias": "  - global_mmlu_full_fr_college_physics", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_computer_security": {"alias": "  - global_mmlu_full_fr_computer_security", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_conceptual_physics": {"alias": "  - global_mmlu_full_fr_conceptual_physics", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_electrical_engineering": {"alias": "  - global_mmlu_full_fr_electrical_engineering", "acc,none": 1.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_elementary_mathematics": {"alias": "  - global_mmlu_full_fr_elementary_mathematics", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_biology": {"alias": "  - global_mmlu_full_fr_high_school_biology", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_chemistry": {"alias": "  - global_mmlu_full_fr_high_school_chemistry", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_computer_science": {"alias": "  - global_mmlu_full_fr_high_school_computer_science", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_mathematics": {"alias": "  - global_mmlu_full_fr_high_school_mathematics", "acc,none": 1.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_physics": {"alias": "  - global_mmlu_full_fr_high_school_physics", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_high_school_statistics": {"alias": "  - global_mmlu_full_fr_high_school_statistics", "acc,none": 0.0, "acc_stderr,none": "N/A"}, "global_mmlu_full_fr_machine_learning": {"alias": "  - global_mmlu_full_fr_machine_learning", "acc,none": 1.0, "acc_stderr,none": "N/A"}}, "groups": {"global_mmlu_full_fr": {"acc,none": 0.17543859649122806, "acc_stderr,none": "N/A", "alias": "global_mmlu_full_fr"}, "global_mmlu_full_fr_humanities": {"acc,none": 0.3076923076923077, "acc_stderr,none": "N/A", "alias": " - global_mmlu_full_fr_humanities"}, "global_mmlu_full_fr_other": {"acc,none": 0.07692307692307693, "acc_stderr,none": "N/A", "alias": " - global_mmlu_full_fr_other"}, "global_mmlu_full_fr_social_sciences": {"acc,none": 0.08333333333333333, "acc_stderr,none": "N/A", "alias": " - global_mmlu_full_fr_social_sciences"}, "global_mmlu_full_fr_stem": {"acc,none": 0.21052631578947367, "acc_stderr,none": "N/A", "alias": " - global_mmlu_full_fr_stem"}}, "group_subtasks": {"global_mmlu_full_fr_humanities": ["global_mmlu_full_fr_high_school_world_history", "global_mmlu_full_fr_formal_logic", "global_mmlu_full_fr_international_law", "global_mmlu_full_fr_moral_disputes", "global_mmlu_full_fr_world_religions", "global_mmlu_full_fr_jurisprudence", "global_mmlu_full_fr_logical_fallacies", "global_mmlu_full_fr_high_school_us_history", "global_mmlu_full_fr_high_school_european_history", "global_mmlu_full_fr_philosophy", "global_mmlu_full_fr_moral_scenarios", "global_mmlu_full_fr_prehistory", "global_mmlu_full_fr_professional_law"], "global_mmlu_full_fr_social_sciences": ["global_mmlu_full_fr_high_school_psychology", "global_mmlu_full_fr_public_relations", "global_mmlu_full_fr_high_school_macroeconomics", "global_mmlu_full_fr_high_school_government_and_politics", "global_mmlu_full_fr_high_school_microeconomics", "global_mmlu_full_fr_sociology", "global_mmlu_full_fr_econometrics", "global_mmlu_full_fr_human_sexuality", "global_mmlu_full_fr_professional_psychology", "global_mmlu_full_fr_high_school_geography", "global_mmlu_full_fr_us_foreign_policy", "global_mmlu_full_fr_security_studies"], "global_mmlu_full_fr_other": ["global_mmlu_full_fr_management", "global_mmlu_full_fr_virology", "global_mmlu_full_fr_human_aging", "global_mmlu_full_fr_nutrition", "global_mmlu_full_fr_professional_medicine", "global_mmlu_full_fr_medical_genetics", "global_mmlu_full_fr_professional_accounting", "global_mmlu_full_fr_clinical_knowledge", "global_mmlu_full_fr_global_facts", "global_mmlu_full_fr_miscellaneous", "global_mmlu_full_fr_marketing", "global_mmlu_full_fr_college_medicine", "global_mmlu_full_fr_business_ethics"], "global_mmlu_full_fr_stem": ["global_mmlu_full_fr_college_computer_science", "global_mmlu_full_fr_college_physics", "global_mmlu_full_fr_high_school_chemistry", "global_mmlu_full_fr_astronomy", "global_mmlu_full_fr_elementary_mathematics", "global_mmlu_full_fr_anatomy", "global_mmlu_full_fr_college_mathematics", "global_mmlu_full_fr_high_school_computer_science", "global_mmlu_full_fr_high_school_mathematics", "global_mmlu_full_fr_computer_security", "global_mmlu_full_fr_abstract_algebra", "global_mmlu_full_fr_conceptual_physics", "global_mmlu_full_fr_high_school_statistics", "global_mmlu_full_fr_machine_learning", "global_mmlu_full_fr_high_school_biology", "global_mmlu_full_fr_electrical_engineering", "global_mmlu_full_fr_college_chemistry", "global_mmlu_full_fr_college_biology", "global_mmlu_full_fr_high_school_physics"], "global_mmlu_full_fr": ["global_mmlu_full_fr_stem", "global_mmlu_full_fr_other", "global_mmlu_full_fr_social_sciences", "global_mmlu_full_fr_humanities"]}, "configs": {"global_mmlu_full_fr_abstract_algebra": {"task": "global_mmlu_full_fr_abstract_algebra", "tag": "global_mmlu_full_fr_stem_tasks", "dataset_path": "CohereForAI/Global-MMLU", "dataset_name": "fr", "test_split": "test", "fewshot_split": "dev", "process_docs": "functools.partial(<function process_docs at 0x7a2f38ac00e0>, subject='abstract_algebra')", "doc_to_text": "{{question.strip()}}\nA. {{option_a}}\nB. {{option_b}}\nC. {{option_c}}\nD. {{option_d}}\nAnswer:", "doc_to_target": "answer", "unsafe_code": false, "doc_to_choice": ["A", "B", "C", "D"], "description": "", "target_delimiter": " ", "fewshot_delimiter": "\n\n", "fewshot_config": {"sampler": "first_n"}, "num_fewshot": 0, "metric_list": [{"metric": "acc", "aggregation": "mean", "higher_is_better": true}], "output_type": "multiple_choice", "repeats": 1, "should_decontaminate": false, "metadata": {"version": 0.0}}, "global_mmlu_full_fr_anatomy": {"task": "global_mmlu_full_fr_anatomy", "tag": "global_mmlu_full_fr_stem_tasks", "dataset_path": "CohereForAI/Global-MMLU", "dataset_name": "fr", "test_split": "test", "fewshot_split": "dev", "process_docs": "functools.partial(<function process_docs at 0x7a2fb0b4bf60>, subject='anatomy')", "doc_to_text": "{{question.strip()}}\nA. {{option_a}}\nB. {{option_b}}\nC. {{option_c}}\nD. {{option_d}}\nAnswer:", "doc_to_target": "answer", "unsafe_code": false, "doc_to_choice": ["A", "B", "C", "D"], "description": "", "target_delimiter": " ", "fewshot_delimiter": "\n\n", "fewshot_config": {"sampler": "first_n"}, "num_fewshot": 0, "metric_list": [{"metric": "acc", "aggregation": "mean", "higher_is_better": true}], "output_type": "multiple_choice", "repeats": 1, "should_decontaminate": false, "metadata": {"version": 0.0}}}}